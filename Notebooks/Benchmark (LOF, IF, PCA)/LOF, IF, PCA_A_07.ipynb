{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.krummenacher\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "found 0 physical cores < 1\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"c:\\Users\\s.krummenacher\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 282, in _count_physical_cores\n",
      "    raise ValueError(f\"found {cpu_count_physical} physical cores < 1\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import (roc_auc_score, recall_score, precision_score, f1_score, roc_curve,\n",
    "                             confusion_matrix, ConfusionMatrixDisplay)\n",
    "import pandas as pd\n",
    "\n",
    "# Paths to audio files\n",
    "anomalous_audio_path = \"../Data/raw/11_A_09_experiment7/A_09_10_experiment7_8.wav\"\n",
    "normal_audio_path = \"../Data/raw/11_A_09_experiment7/N_09_experiment7.wav\"\n",
    "\n",
    "# Paths for saving frames and datasets\n",
    "output_anomalous_frames_path = \"../Data/frames/anomalous_frames.npy\"\n",
    "output_normal_frames_path = \"../Data/frames/normal_frames.npy\"\n",
    "train_frames_path = \"../Data/datasets/train_frames.npy\"\n",
    "test_frames_path = \"../Data/datasets/test_frames.npy\"\n",
    "test_labels_path = \"../Data/datasets/test_labels.npy\"\n",
    "\n",
    "# Ensure necessary directories exist\n",
    "os.makedirs(os.path.dirname(output_anomalous_frames_path), exist_ok=True)\n",
    "os.makedirs(os.path.dirname(train_frames_path), exist_ok=True)\n",
    "\n",
    "# Function to generate a normalized Mel-spectrogram\n",
    "def generate_mel_spectrogram(audio_path):\n",
    "    audio, sr = librosa.load(audio_path, sr=None)\n",
    "    stft = librosa.stft(audio, n_fft=1024, hop_length=512)\n",
    "    mel = librosa.feature.melspectrogram(S=np.abs(stft)**2, sr=sr, n_mels=128)\n",
    "    mel_db = librosa.power_to_db(mel, ref=np.max)\n",
    "    # Normalize to [0, 1]\n",
    "    mel_db_norm = (mel_db - mel_db.min()) / (mel_db.max() - mel_db.min())\n",
    "    return mel_db_norm, sr\n",
    "\n",
    "# Function to generate overlapping frames from a Mel-spectrogram\n",
    "def generate_frames(mel_spectrogram, frame_size, hop_size):\n",
    "    num_frames = (mel_spectrogram.shape[1] - frame_size) // hop_size + 1\n",
    "    frames = np.zeros((num_frames, mel_spectrogram.shape[0], frame_size))\n",
    "    for i in range(num_frames):\n",
    "        start = i * hop_size\n",
    "        frames[i] = mel_spectrogram[:, start:start + frame_size]\n",
    "    return frames\n",
    "\n",
    "# Adjustable parameters\n",
    "time_per_frame = 0.4  # Duration of one frame in seconds\n",
    "hop_ratio = 0.2       # Overlap ratio between frames\n",
    "\n",
    "# Generate Mel-spectrograms\n",
    "mel_db_anomalous, sr_anomalous = generate_mel_spectrogram(anomalous_audio_path)\n",
    "mel_db_normal, sr_normal = generate_mel_spectrogram(normal_audio_path)\n",
    "\n",
    "# Ensure sampling rates match\n",
    "assert sr_anomalous == sr_normal, \"Sampling rates do not match!\"\n",
    "\n",
    "# Calculate frame and hop sizes\n",
    "hop_length = 512\n",
    "frame_size = int((time_per_frame * sr_anomalous) / hop_length)\n",
    "hop_size = int(frame_size * hop_ratio)\n",
    "\n",
    "# Generate frames\n",
    "anomalous_frames = generate_frames(mel_db_anomalous, frame_size, hop_size)\n",
    "normal_frames = generate_frames(mel_db_normal, frame_size, hop_size)\n",
    "\n",
    "# Save frames\n",
    "np.save(output_anomalous_frames_path, anomalous_frames)\n",
    "np.save(output_normal_frames_path, normal_frames)\n",
    "\n",
    "# Load frames\n",
    "anomalous_frames = np.load(output_anomalous_frames_path)\n",
    "normal_frames = np.load(output_normal_frames_path)\n",
    "\n",
    "# Get the number of Mel bands and frame size for reshaping later\n",
    "num_mels = anomalous_frames.shape[1]\n",
    "\n",
    "# Split normal frames into training and test sets\n",
    "normal_train, normal_test = train_test_split(normal_frames, test_size=0.15, random_state=42)\n",
    "\n",
    "# Combine normal_test and anomalous_frames for testing\n",
    "test_frames = np.concatenate([normal_test, anomalous_frames], axis=0)\n",
    "test_labels = np.concatenate([np.zeros(len(normal_test)), np.ones(len(anomalous_frames))])\n",
    "\n",
    "# Shuffle the test set\n",
    "indices = np.arange(len(test_frames))\n",
    "np.random.shuffle(indices)\n",
    "test_frames = test_frames[indices]\n",
    "test_labels = test_labels[indices]\n",
    "\n",
    "# Save datasets\n",
    "np.save(train_frames_path, normal_train)\n",
    "np.save(test_frames_path, test_frames)\n",
    "np.save(test_labels_path, test_labels)\n",
    "\n",
    "# Load datasets\n",
    "X_train = np.load(train_frames_path)\n",
    "X_test = np.load(test_frames_path)\n",
    "y_test = np.load(test_labels_path)\n",
    "\n",
    "# Flatten the frames for model input\n",
    "X_train_flat = X_train.reshape(len(X_train), -1)\n",
    "X_test_flat = X_test.reshape(len(X_test), -1)\n",
    "\n",
    "# Adjust labels: 1 for normal, -1 for anomalous\n",
    "y_test_adjusted = np.where(y_test == 0, 1, -1)\n",
    "\n",
    "# Define the classify_anomalies function with adjustments\n",
    "def classify_anomalies(train_data, test_data, test_labels, machine, feat_label):\n",
    "    scaler = MinMaxScaler(feature_range=(-5, 5))\n",
    "    \n",
    "    # LOF without PCA\n",
    "    lof = LocalOutlierFactor(novelty=True, contamination=0.1)\n",
    "    lof_pipe = Pipeline([(\"scaler\", scaler), (\"classifier\", lof)])\n",
    "    \n",
    "    # LOF with PCA\n",
    "    pca_lof = PCA(0.9)\n",
    "    lof_pca_pipe = Pipeline([(\"scaler\", scaler), (\"pca\", pca_lof), (\"classifier\", lof)])\n",
    "    \n",
    "    # Isolation Forest without PCA\n",
    "    isolation_forest = IsolationForest(contamination=0.1, random_state=42)\n",
    "    isolation_forest_pipe = Pipeline([(\"scaler\", scaler), (\"classifier\", isolation_forest)])\n",
    "    \n",
    "    # Isolation Forest with PCA\n",
    "    pca_if = PCA(0.9)\n",
    "    isolation_forest_pca_pipe = Pipeline([(\"scaler\", scaler), (\"pca\", pca_if), (\"classifier\", isolation_forest)])\n",
    "    \n",
    "    models = {\n",
    "        \"LOF\": lof_pipe,\n",
    "        \"LOF + PCA\": lof_pca_pipe,\n",
    "        \"Isolation Forest\": isolation_forest_pipe,\n",
    "        \"Isolation Forest + PCA\": isolation_forest_pca_pipe,\n",
    "    }\n",
    "    \n",
    "    results = {\n",
    "        \"Machine\": machine,\n",
    "        \"Features\": feat_label,\n",
    "        \"Model\": [],\n",
    "        \"AUC\": [],\n",
    "        \"Recall\": [],\n",
    "        \"Precision\": [],\n",
    "        \"Abnormal (-1) F1\": [],\n",
    "    }\n",
    "    \n",
    "    model_results = []\n",
    "    \n",
    "    fig, axes = plt.subplots(ncols=len(models), nrows=1, figsize=(16, 4))\n",
    "\n",
    "    for i, (model_name, model) in enumerate(models.items()):\n",
    "        roc_ax = axes[i]\n",
    "        model.fit(train_data)\n",
    "        scores = model.decision_function(test_data)\n",
    "        auc = roc_auc_score(test_labels, scores)\n",
    "        fpr, tpr, thresholds = roc_curve(test_labels, scores)\n",
    "        \n",
    "        roc_ax.plot(fpr, tpr)\n",
    "        roc_ax.plot([0, 1], [0, 1], linestyle='--', color='gray', alpha=0.7)\n",
    "        roc_ax.set_title(f'{model_name}\\n ROC Curve\\n AUC = {auc:.2f}')\n",
    "        roc_ax.set_xlabel('False Positive Rate')\n",
    "        roc_ax.set_ylabel('True Positive Rate')\n",
    "        roc_ax.legend(['ROC curve', 'Random'], fontsize=\"9\", loc='lower right')\n",
    "\n",
    "        # Threshold for 85% correctly classified normal data\n",
    "        sorted_scores = np.sort(scores[test_labels == 1])\n",
    "        threshold_index = int(0.85 * len(sorted_scores))\n",
    "        threshold = sorted_scores[threshold_index]\n",
    "        predictions = np.where(scores >= threshold, 1, -1)\n",
    "\n",
    "        recall = recall_score(test_labels, predictions, pos_label=-1)\n",
    "        precision = precision_score(test_labels, predictions, pos_label=-1)\n",
    "        abf1 = f1_score(test_labels, predictions, pos_label=-1)\n",
    "        \n",
    "        # Compute confusion matrix\n",
    "        conf_matrix = confusion_matrix(test_labels, predictions)\n",
    "\n",
    "        results[\"Model\"].append(model_name)\n",
    "        results[\"AUC\"].append(auc)\n",
    "        results[\"Recall\"].append(recall)\n",
    "        results[\"Precision\"].append(precision)\n",
    "        results[\"Abnormal (-1) F1\"].append(abf1)\n",
    "        \n",
    "        # Store results for this model\n",
    "        model_results.append({\n",
    "            \"model_name\": model_name,\n",
    "            \"scores\": scores,\n",
    "            \"predictions\": predictions,\n",
    "            \"conf_matrix\": conf_matrix,\n",
    "            \"roc_auc\": auc,\n",
    "            \"fpr\": fpr,\n",
    "            \"tpr\": tpr,\n",
    "            \"thresholds\": thresholds,\n",
    "        })\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    print(f\"{feat_label} features were reduced to {pca_lof.n_components_} components for LOF\")\n",
    "    print(f\"{feat_label} features were reduced to {pca_if.n_components_} components for Isolation Forest\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return results_df, model_results\n",
    "\n",
    "# Run the classification\n",
    "results_df, model_results = classify_anomalies(X_train_flat, X_test_flat, y_test_adjusted, \"Hydropower Machine\", \"Mel-Spectrogram Frames\")\n",
    "print(results_df)\n",
    "\n",
    "# Select the best model based on AUC\n",
    "best_model_index = np.argmax(results_df['AUC'])\n",
    "best_model_name = results_df['Model'][best_model_index]\n",
    "print(f\"Best model based on AUC: {best_model_name}\")\n",
    "\n",
    "# Get the results for the best model\n",
    "best_model_results = model_results[best_model_index]\n",
    "\n",
    "predictions = best_model_results['predictions']\n",
    "scores = best_model_results['scores']\n",
    "conf_matrix = best_model_results['conf_matrix']\n",
    "roc_auc = best_model_results['roc_auc']\n",
    "fpr = best_model_results['fpr']\n",
    "tpr = best_model_results['tpr']\n",
    "thresholds = best_model_results['thresholds']\n",
    "\n",
    "# Reshape test_frames back to original shape for plotting\n",
    "frame_size = X_test_flat.shape[1] // num_mels\n",
    "test_frames_reshaped = X_test_flat.reshape(-1, num_mels, frame_size)\n",
    "\n",
    "# Identify indices\n",
    "correctly_classified_anomalies = np.where((y_test_adjusted == -1) & (predictions == -1))[0]\n",
    "wrongly_classified_anomalies = np.where((y_test_adjusted == -1) & (predictions == 1))[0]\n",
    "wrongly_classified_normals = np.where((y_test_adjusted == 1) & (predictions == -1))[0]\n",
    "\n",
    "# Select up to 5 samples from each category\n",
    "num_samples = 5\n",
    "correct_anomaly_indices = correctly_classified_anomalies[:num_samples]\n",
    "wrong_anomaly_indices = wrongly_classified_anomalies[:num_samples]\n",
    "wrong_normal_indices = wrongly_classified_normals[:num_samples]\n",
    "\n",
    "# Function to plot specified frames\n",
    "def plot_specified_frames(frames, indices, title_prefix=\"Frame\"):\n",
    "    num_frames = len(indices)\n",
    "    fig, axes = plt.subplots(1, num_frames, figsize=(15, 5))\n",
    "    for i, idx in enumerate(indices):\n",
    "        ax = axes[i] if num_frames > 1 else axes\n",
    "        img = librosa.display.specshow(frames[idx], x_axis=None, y_axis=\"mel\", cmap=\"viridis\", ax=ax)\n",
    "        ax.set_title(f\"{title_prefix} {i+1}\")\n",
    "        ax.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot frames\n",
    "print(\"Correctly Classified Anomalies:\")\n",
    "if len(correct_anomaly_indices) > 0:\n",
    "    plot_specified_frames(test_frames_reshaped, correct_anomaly_indices, title_prefix=\"Correct Anomaly\")\n",
    "else:\n",
    "    print(\"No correctly classified anomalies.\")\n",
    "\n",
    "print(\"Wrongly Classified Anomalies:\")\n",
    "if len(wrong_anomaly_indices) > 0:\n",
    "    plot_specified_frames(test_frames_reshaped, wrong_anomaly_indices, title_prefix=\"Wrongly Classified Anomaly\")\n",
    "else:\n",
    "    print(\"No wrongly classified anomalies.\")\n",
    "\n",
    "print(\"Wrongly Classified Normal Frames:\")\n",
    "if len(wrong_normal_indices) > 0:\n",
    "    plot_specified_frames(test_frames_reshaped, wrong_normal_indices, title_prefix=\"Wrongly Classified Normal\")\n",
    "else:\n",
    "    print(\"No wrongly classified normal frames.\")\n",
    "\n",
    "# Plot Confusion Matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=['Normal', 'Anomalous'])\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(f'Confusion Matrix for {best_model_name}')\n",
    "plt.show()\n",
    "\n",
    "# Plot ROC Curve\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0,1], [0,1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title(f'Receiver Operating Characteristic for {best_model_name}')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
